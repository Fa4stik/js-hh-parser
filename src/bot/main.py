#!/usr/bin/env python3
"""
Telegram –±–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–∞–∫–∞–Ω—Å–∏–π.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ.
"""

import os
import logging
import asyncio
import threading
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes
from vacancy_processor import VacancyProcessor
from meta import BOT_TOKEN

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–π
processor = VacancyProcessor("merged_vacs.xlsx")

# –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
processing_active = False
processing_thread = None


def process_vacancies_background():
    """–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π"""
    global processing_active
    
    try:
        logger.info("–ù–∞—á–∏–Ω–∞—é —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π...")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π
        total_rows = processor.get_total_rows()
        logger.info(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_rows}")
        
        if total_rows == 0:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
            processing_active = False
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—Ç—å (–ø—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
        process_dir = processor.output_dir
        csv_files = []
        max_offset = 0
        
        if os.path.exists(process_dir):
            csv_files = [f for f in os.listdir(process_dir) if f.endswith('.csv')]
            if csv_files:
                # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π offset –∏–∑ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
                offsets = []
                for file in csv_files:
                    try:
                        offset = int(file.replace('.csv', ''))
                        offsets.append(offset)
                    except ValueError:
                        continue
                if offsets:
                    max_offset = max(offsets)
        
        start_row = max_offset
        processed_count = len(csv_files) * 100
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(csv_files)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π offset: {max_offset}")
        logger.info(f"–ù–∞—á–∏–Ω–∞—é —Å —Å—Ç—Ä–æ–∫–∏: {start_row}")
        
        batch_size = 100
        current_row = start_row
        batch_count = 0
        
        while current_row < total_rows and processing_active:
            logger.info(f"--- –ë–∞—Ç—á {batch_count + 1} ---")
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ {current_row} - {min(current_row + batch_size, total_rows)}")
            
            # –ß–∏—Ç–∞–µ–º –±–∞—Ç—á –≤–∞–∫–∞–Ω—Å–∏–π
            vacancies = processor.read_vacancies_batch(batch_size, current_row)
            
            if not vacancies:
                logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —ç—Ç–æ–º –±–∞—Ç—á–µ")
                break
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ –±–∞—Ç—á–∞")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
            offset = current_row + len(vacancies)
            success = processor.process_batch(vacancies, offset)
            
            if success:
                logger.info(f"–ë–∞—Ç—á —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {offset}.csv")
                new_processed_count = processor.get_processed_count()
                logger.info(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {new_processed_count}")
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {offset}")
                break
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É
            current_row += len(vacancies)
            batch_count += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = (current_row / total_rows) * 100
            logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({current_row}/{total_rows})")
        
        logger.info("–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        final_count = processor.get_processed_count()
        logger.info(f"–ò—Ç–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {final_count}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
    finally:
        processing_active = False


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    welcome_text = """
ü§ñ –ë–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–∞–∫–∞–Ω—Å–∏–π

üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞!

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/get_process - –ø–æ–∫–∞–∑–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
/merge_vacs - –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω
/merge_by_id - –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
/start_processing - –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Ä—É—á–Ω—É—é
/stop_processing - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
"""
    await update.message.reply_text(welcome_text)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø—Ä–∞–≤–∫—É –ø–æ –∫–æ–º–∞–Ω–¥–∞–º."""
    help_text = """
üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:

/get_process - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
–°—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ process_vacs √ó 100

/merge_vacs - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω merged_results.csv
–ü–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

/merge_by_id - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º
–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ soft_skills –∏ hard_skills –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º

/start_processing - –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π –≤—Ä—É—á–Ω—É—é
–ü–æ–ª–µ–∑–Ω–æ –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞

/stop_processing - –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É

/help - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ

‚ÑπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
"""
    await update.message.reply_text(help_text)


async def get_process(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π."""
    try:
        processed_count = processor.get_processed_count()
        total_rows = processor.get_total_rows()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        process_dir = processor.output_dir
        csv_files = []
        if os.path.exists(process_dir):
            csv_files = sorted([f for f in os.listdir(process_dir) if f.endswith('.csv')])
        
        status_icon = "üîÑ" if processing_active else "‚è∏Ô∏è"
        status_text = "–∞–∫—Ç–∏–≤–Ω–∞" if processing_active else "–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
        
        message = f"""
üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π:

{status_icon} –û–±—Ä–∞–±–æ—Ç–∫–∞: {status_text}
‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {processed_count}
üìÅ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}
üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_rows}

"""
        
        if total_rows > 0:
            progress = (processed_count / total_rows) * 100
            message += f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%\n"
        
        if csv_files:
            message += f"\nüìÇ –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã:\n"
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ñ–∞–π–ª–æ–≤
            for file in csv_files[-5:]:
                message += f"‚Ä¢ {file}\n"
        
        await update.message.reply_text(message)
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in get_process: {e}")


async def start_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π –≤—Ä—É—á–Ω—É—é."""
    global processing_active, processing_thread
    
    try:
        if processing_active:
            await update.message.reply_text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –∞–∫—Ç–∏–≤–Ω–∞!")
            return
        
        await update.message.reply_text("üöÄ –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π...")
        
        processing_active = True
        processing_thread = threading.Thread(target=process_vacancies_background)
        processing_thread.daemon = True
        processing_thread.start()
        
        await update.message.reply_text("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in start_processing: {e}")


async def stop_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π."""
    global processing_active
    
    try:
        if not processing_active:
            await update.message.reply_text("‚è∏Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
            return
        
        processing_active = False
        await update.message.reply_text("‚èπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in stop_processing: {e}")


async def merge_vacs(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω."""
    try:
        await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ CSV —Ñ–∞–π–ª–æ–≤...")
        
        result = processor.merge_all_csv_files()
        
        message = f"‚úÖ {result}"
        await update.message.reply_text(message)
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in merge_vacs: {e}")


async def merge_by_id(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º."""
    try:
        await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º...")
        
        result = processor.merge_with_original()
        
        message = f"‚úÖ {result}"
        await update.message.reply_text(message)
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in merge_by_id: {e}")


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫."""
    logger.error(f"Update {update} caused error {context.error}")


def start_background_processing():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞"""
    global processing_active, processing_thread
    
    logger.info("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π...")
    processing_active = True
    processing_thread = threading.Thread(target=process_vacancies_background)
    processing_thread.daemon = True
    processing_thread.start()


def main() -> None:
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞."""
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(BOT_TOKEN).build()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("get_process", get_process))
    application.add_handler(CommandHandler("start_processing", start_processing))
    application.add_handler(CommandHandler("stop_processing", stop_processing))
    application.add_handler(CommandHandler("merge_vacs", merge_vacs))
    application.add_handler(CommandHandler("merge_by_id", merge_by_id))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    application.add_error_handler(error_handler)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    start_background_processing()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    logger.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞–ø—É—â–µ–Ω–∞!")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
