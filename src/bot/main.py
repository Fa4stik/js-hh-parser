#!/usr/bin/env python3
"""
Telegram –±–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–∞–∫–∞–Ω—Å–∏–π.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ.
"""

import os
import logging
import asyncio
import threading
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes, MessageHandler, filters, ConversationHandler
from vacancy_processor import VacancyProcessor
from meta import BOT_TOKEN

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–π
processor = VacancyProcessor("merged_vacs.xlsx")

# –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
processing_active = False
processing_thread = None

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
GET_OFFSET = 0


def process_vacancies_background():
    """–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π"""
    global processing_active
    
    try:
        logger.info("–ù–∞—á–∏–Ω–∞—é —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π...")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π
        total_rows = processor.get_total_rows()
        logger.info(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_rows}")
        
        if total_rows == 0:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
            processing_active = False
            return
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—Ç—å (–ø—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
        process_dir = processor.output_dir
        csv_files = []
        max_offset = 0
        
        if os.path.exists(process_dir):
            csv_files = [f for f in os.listdir(process_dir) if f.endswith('.csv')]
            if csv_files:
                # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π offset –∏–∑ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
                offsets = []
                for file in csv_files:
                    try:
                        offset = int(file.replace('.csv', ''))
                        offsets.append(offset)
                    except ValueError:
                        continue
                if offsets:
                    max_offset = max(offsets)
        
        start_row = max_offset
        processed_count = len(csv_files) * 100
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(csv_files)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π offset: {max_offset}")
        logger.info(f"–ù–∞—á–∏–Ω–∞—é —Å —Å—Ç—Ä–æ–∫–∏: {start_row}")
        
        batch_size = 100
        current_row = start_row
        batch_count = 0
        
        while current_row < total_rows and processing_active:
            logger.info(f"--- –ë–∞—Ç—á {batch_count + 1} ---")
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ {current_row} - {min(current_row + batch_size, total_rows)}")
            
            # –ß–∏—Ç–∞–µ–º –±–∞—Ç—á –≤–∞–∫–∞–Ω—Å–∏–π
            vacancies = processor.read_vacancies_batch(batch_size, current_row)
            
            if not vacancies:
                logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —ç—Ç–æ–º –±–∞—Ç—á–µ")
                break
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ –±–∞—Ç—á–∞")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
            offset = current_row + len(vacancies)
            success = processor.process_batch(vacancies, offset)
            
            if success:
                logger.info(f"–ë–∞—Ç—á —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {offset}.csv")
                new_processed_count = processor.get_processed_count()
                logger.info(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {new_processed_count}")
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {offset}")
                break
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É
            current_row += len(vacancies)
            batch_count += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = (current_row / total_rows) * 100
            logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({current_row}/{total_rows})")
        
        logger.info("–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        final_count = processor.get_processed_count()
        logger.info(f"–ò—Ç–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {final_count}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
    finally:
        processing_active = False


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    welcome_text = """
ü§ñ –ë–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–∞–∫–∞–Ω—Å–∏–π

üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞!

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/get_process - –ø–æ–∫–∞–∑–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
/get_by_offset - –ø–æ–ª—É—á–∏—Ç—å CSV —Ñ–∞–π–ª –ø–æ offset
/merge_vacs - –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω
/merge_by_id - –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º (—Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
/start_processing - –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Ä—É—á–Ω—É—é
/stop_processing - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
"""
    await update.message.reply_text(welcome_text)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø—Ä–∞–≤–∫—É –ø–æ –∫–æ–º–∞–Ω–¥–∞–º."""
    help_text = """
üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:

/get_process - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π
–°—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ process_vacs √ó 100

/get_by_offset - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç CSV —Ñ–∞–π–ª –ø–æ offset
–í–≤–µ–¥–∏—Ç–µ offset (4 = 100.csv, 150 = 200.csv –∏ —Ç.–¥.)

/merge_vacs - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω merged_results.csv
–ü–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

/merge_by_id - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º
–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (–Ω–µ –≤–µ—Å—å —Ñ–∞–π–ª)

/start_processing - –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π –≤—Ä—É—á–Ω—É—é
–ü–æ–ª–µ–∑–Ω–æ –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞

/stop_processing - –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É

/help - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ

‚ÑπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
"""
    await update.message.reply_text(help_text)


async def get_process(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π."""
    try:
        processed_count = processor.get_processed_count()
        total_rows = processor.get_total_rows()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        process_dir = processor.output_dir
        csv_files = []
        if os.path.exists(process_dir):
            csv_files = sorted([f for f in os.listdir(process_dir) if f.endswith('.csv')])
        
        status_icon = "üîÑ" if processing_active else "‚è∏Ô∏è"
        status_text = "–∞–∫—Ç–∏–≤–Ω–∞" if processing_active else "–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
        
        message = f"""
üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π:

{status_icon} –û–±—Ä–∞–±–æ—Ç–∫–∞: {status_text}
‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {processed_count}
üìÅ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}
üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_rows}

"""
        
        if total_rows > 0:
            progress = (processed_count / total_rows) * 100
            message += f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%\n"
        
        if csv_files:
            message += f"\nüìÇ –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã:\n"
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ñ–∞–π–ª–æ–≤
            for file in csv_files[-5:]:
                message += f"‚Ä¢ {file}\n"
        
        await update.message.reply_text(message)
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in get_process: {e}")


async def start_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π –≤—Ä—É—á–Ω—É—é."""
    global processing_active, processing_thread
    
    try:
        if processing_active:
            await update.message.reply_text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –∞–∫—Ç–∏–≤–Ω–∞!")
            return
        
        await update.message.reply_text("üöÄ –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π...")
        
        processing_active = True
        processing_thread = threading.Thread(target=process_vacancies_background)
        processing_thread.daemon = True
        processing_thread.start()
        
        await update.message.reply_text("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in start_processing: {e}")


async def stop_processing(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∞–∫–∞–Ω—Å–∏–π."""
    global processing_active
    
    try:
        if not processing_active:
            await update.message.reply_text("‚è∏Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
            return
        
        processing_active = False
        await update.message.reply_text("‚èπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in stop_processing: {e}")


async def get_by_offset_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–ù–∞—á–∏–Ω–∞–µ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø–æ offset"""
    await update.message.reply_text(
        "üìÅ –í–≤–µ–¥–∏—Ç–µ offset –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è CSV —Ñ–∞–π–ª–∞:\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ 4 ‚Üí –≤–µ—Ä–Ω–µ—Ç 100.csv\n"
        "‚Ä¢ 150 ‚Üí –≤–µ—Ä–Ω–µ—Ç 200.csv\n"
        "‚Ä¢ 250 ‚Üí –≤–µ—Ä–Ω–µ—Ç 300.csv\n\n"
        "–ò–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã"
    )
    return GET_OFFSET


async def get_by_offset_handle(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–µ–¥–µ–Ω–Ω—ã–π offset"""
    try:
        user_input = update.message.text.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—É –æ—Ç–º–µ–Ω—ã
        if user_input.lower() in ['/cancel', '–æ—Ç–º–µ–Ω–∞']:
            await update.message.reply_text("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return ConversationHandler.END
        
        # –ü–∞—Ä—Å–∏–º offset
        try:
            offset = int(user_input)
        except ValueError:
            await update.message.reply_text("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ /cancel")
            return GET_OFFSET
        
        if offset <= 0:
            await update.message.reply_text("‚ùå Offset –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º")
            return GET_OFFSET
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ offset
        # offset 4 ‚Üí 100.csv, offset 150 ‚Üí 200.csv
        file_offset = ((offset - 1) // 100 + 1) * 100
        filename = f"{file_offset}.csv"
        filepath = os.path.join(processor.output_dir, filename)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(filepath):
            await update.message.reply_text(
                f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω!\n"
                f"Offset {offset} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª—É {filename}, –∫–æ—Ç–æ—Ä—ã–π –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω."
            )
            return ConversationHandler.END
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
        await update.message.reply_text(f"üìÑ –û—Ç–ø—Ä–∞–≤–ª—è—é —Ñ–∞–π–ª {filename}...")
        
        with open(filepath, 'rb') as file:
            await update.message.reply_document(
                document=file,
                filename=filename,
                caption=f"CSV —Ñ–∞–π–ª –¥–ª—è offset {offset} (—Ñ–∞–π–ª {filename})"
            )
        
        return ConversationHandler.END
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in get_by_offset_handle: {e}")
        return ConversationHandler.END


async def cancel_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """–û—Ç–º–µ–Ω—è–µ—Ç –¥–∏–∞–ª–æ–≥"""
    await update.message.reply_text("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
    return ConversationHandler.END


async def merge_vacs(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª."""
    try:
        await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ CSV —Ñ–∞–π–ª–æ–≤...")
        
        result = processor.merge_all_csv_files()
        
        # –ü—É—Ç—å –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        merged_file_path = os.path.join(processor.output_dir, "merged_results.csv")
        
        if os.path.exists(merged_file_path):
            await update.message.reply_text(f"‚úÖ {result}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            with open(merged_file_path, 'rb') as file:
                await update.message.reply_document(
                    document=file,
                    filename="merged_results.csv",
                    caption="–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏—è–º–∏"
                )
        else:
            await update.message.reply_text(f"‚ö†Ô∏è {result}")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in merge_vacs: {e}")


async def merge_by_id(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º (—Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)."""
    try:
        await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º...")
        await update.message.reply_text("üìä –≠—Ç–∞–ø 1: –û–±—ä–µ–¥–∏–Ω—è—é –≤—Å–µ CSV —Ñ–∞–π–ª—ã...")
        
        # –°–Ω–∞—á–∞–ª–∞ –º–µ—Ä–∂–∏–º –≤—Å–µ CSV
        merge_result = processor.merge_all_csv_files()
        
        await update.message.reply_text("üìã –≠—Ç–∞–ø 2: –û–±—ä–µ–¥–∏–Ω—è—é —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º...")
        
        # –ó–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
        result = processor.merge_with_original()
        
        # –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º—É —Ñ–∞–π–ª—É
        result_file_path = os.path.join(processor.output_dir, "merged_with_original.xlsx")
        
        if os.path.exists(result_file_path):
            await update.message.reply_text(f"‚úÖ {result}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            with open(result_file_path, 'rb') as file:
                await update.message.reply_document(
                    document=file,
                    filename="merged_with_original.xlsx",
                    caption="–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –Ω–∞–≤—ã–∫–∞–º–∏ (—Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)"
                )
        else:
            await update.message.reply_text(f"‚ö†Ô∏è {result}")
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º: {str(e)}"
        await update.message.reply_text(error_message)
        logger.error(f"Error in merge_by_id: {e}")


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫."""
    logger.error(f"Update {update} caused error {context.error}")


def start_background_processing():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞"""
    global processing_active, processing_thread
    
    logger.info("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π...")
    processing_active = True
    processing_thread = threading.Thread(target=process_vacancies_background)
    processing_thread.daemon = True
    processing_thread.start()


def main() -> None:
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞."""
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(BOT_TOKEN).build()
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ get_by_offset
    get_offset_handler = ConversationHandler(
        entry_points=[CommandHandler("get_by_offset", get_by_offset_start)],
        states={
            GET_OFFSET: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_by_offset_handle)]
        },
        fallbacks=[CommandHandler("cancel", cancel_conversation)]
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("get_process", get_process))
    application.add_handler(get_offset_handler)
    application.add_handler(CommandHandler("start_processing", start_processing))
    application.add_handler(CommandHandler("stop_processing", stop_processing))
    application.add_handler(CommandHandler("merge_vacs", merge_vacs))
    application.add_handler(CommandHandler("merge_by_id", merge_by_id))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    application.add_error_handler(error_handler)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    start_background_processing()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    logger.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞–ø—É—â–µ–Ω–∞!")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
